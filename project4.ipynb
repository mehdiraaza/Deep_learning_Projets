{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPWphMl/7P7qok1eTfoP+Ua"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ditAkvb2k5Tf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":83},"outputId":"a0cdbd70-6d70-4b14-ea06-fd0971a12545","executionInfo":{"status":"ok","timestamp":1579165161046,"user_tz":-300,"elapsed":3280,"user":{"displayName":"Mehdi Raza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFcVtZea7sFjanyXz-m90MCC3neMbLZTIgurt0EA=s64","userId":"02751970470605007695"}}},"source":["import numpy\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.constraints import max_norm\n","from keras.optimizers import SGD\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jPkSPgETk-mU","colab_type":"code","colab":{}},"source":["seed = 7\n","numpy.random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4313sIfplKUC","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":75},"outputId":"1ac7fda3-0a68-4c61-b49e-68c32a0e1ae0","executionInfo":{"status":"ok","timestamp":1579165228527,"user_tz":-300,"elapsed":26457,"user":{"displayName":"Mehdi Raza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFcVtZea7sFjanyXz-m90MCC3neMbLZTIgurt0EA=s64","userId":"02751970470605007695"}}},"source":["import pandas as pd\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-c3a620ca-87e0-49a9-94be-2ad8655cbcf3\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-c3a620ca-87e0-49a9-94be-2ad8655cbcf3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving sonar.csv to sonar.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jrx9lQSilAqP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":427},"outputId":"a01994d9-0c1e-4567-ed2d-3ebcf6f0a9e3","executionInfo":{"status":"ok","timestamp":1579165230922,"user_tz":-300,"elapsed":1293,"user":{"displayName":"Mehdi Raza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFcVtZea7sFjanyXz-m90MCC3neMbLZTIgurt0EA=s64","userId":"02751970470605007695"}}},"source":["df = pd.read_csv('sonar.csv')\n","df"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0.0200</th>\n","      <th>0.0371</th>\n","      <th>0.0428</th>\n","      <th>0.0207</th>\n","      <th>0.0954</th>\n","      <th>0.0986</th>\n","      <th>0.1539</th>\n","      <th>0.1601</th>\n","      <th>0.3109</th>\n","      <th>0.2111</th>\n","      <th>0.1609</th>\n","      <th>0.1582</th>\n","      <th>0.2238</th>\n","      <th>0.0645</th>\n","      <th>0.0660</th>\n","      <th>0.2273</th>\n","      <th>0.3100</th>\n","      <th>0.2999</th>\n","      <th>0.5078</th>\n","      <th>0.4797</th>\n","      <th>0.5783</th>\n","      <th>0.5071</th>\n","      <th>0.4328</th>\n","      <th>0.5550</th>\n","      <th>0.6711</th>\n","      <th>0.6415</th>\n","      <th>0.7104</th>\n","      <th>0.8080</th>\n","      <th>0.6791</th>\n","      <th>0.3857</th>\n","      <th>0.1307</th>\n","      <th>0.2604</th>\n","      <th>0.5121</th>\n","      <th>0.7547</th>\n","      <th>0.8537</th>\n","      <th>0.8507</th>\n","      <th>0.6692</th>\n","      <th>0.6097</th>\n","      <th>0.4943</th>\n","      <th>0.2744</th>\n","      <th>0.0510</th>\n","      <th>0.2834</th>\n","      <th>0.2825</th>\n","      <th>0.4256</th>\n","      <th>0.2641</th>\n","      <th>0.1386</th>\n","      <th>0.1051</th>\n","      <th>0.1343</th>\n","      <th>0.0383</th>\n","      <th>0.0324</th>\n","      <th>0.0232</th>\n","      <th>0.0027</th>\n","      <th>0.0065</th>\n","      <th>0.0159</th>\n","      <th>0.0072</th>\n","      <th>0.0167</th>\n","      <th>0.0180</th>\n","      <th>0.0084</th>\n","      <th>0.0090</th>\n","      <th>0.0032</th>\n","      <th>R</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>0.4918</td>\n","      <td>0.6552</td>\n","      <td>0.6919</td>\n","      <td>0.7797</td>\n","      <td>0.7464</td>\n","      <td>0.9444</td>\n","      <td>1.0000</td>\n","      <td>0.8874</td>\n","      <td>0.8024</td>\n","      <td>0.7818</td>\n","      <td>0.5212</td>\n","      <td>0.4052</td>\n","      <td>0.3957</td>\n","      <td>0.3914</td>\n","      <td>0.3250</td>\n","      <td>0.3200</td>\n","      <td>0.3271</td>\n","      <td>0.2767</td>\n","      <td>0.4423</td>\n","      <td>0.2028</td>\n","      <td>0.3788</td>\n","      <td>0.2947</td>\n","      <td>0.1984</td>\n","      <td>0.2341</td>\n","      <td>0.1306</td>\n","      <td>0.4182</td>\n","      <td>0.3835</td>\n","      <td>0.1057</td>\n","      <td>0.1840</td>\n","      <td>0.1970</td>\n","      <td>0.1674</td>\n","      <td>0.0583</td>\n","      <td>0.1401</td>\n","      <td>0.1628</td>\n","      <td>0.0621</td>\n","      <td>0.0203</td>\n","      <td>0.0530</td>\n","      <td>0.0742</td>\n","      <td>0.0409</td>\n","      <td>0.0061</td>\n","      <td>0.0125</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>0.6333</td>\n","      <td>0.7060</td>\n","      <td>0.5544</td>\n","      <td>0.5320</td>\n","      <td>0.6479</td>\n","      <td>0.6931</td>\n","      <td>0.6759</td>\n","      <td>0.7551</td>\n","      <td>0.8929</td>\n","      <td>0.8619</td>\n","      <td>0.7974</td>\n","      <td>0.6737</td>\n","      <td>0.4293</td>\n","      <td>0.3648</td>\n","      <td>0.5331</td>\n","      <td>0.2413</td>\n","      <td>0.5070</td>\n","      <td>0.8533</td>\n","      <td>0.6036</td>\n","      <td>0.8514</td>\n","      <td>0.8512</td>\n","      <td>0.5045</td>\n","      <td>0.1862</td>\n","      <td>0.2709</td>\n","      <td>0.4232</td>\n","      <td>0.3043</td>\n","      <td>0.6116</td>\n","      <td>0.6756</td>\n","      <td>0.5375</td>\n","      <td>0.4719</td>\n","      <td>0.4647</td>\n","      <td>0.2587</td>\n","      <td>0.2129</td>\n","      <td>0.2222</td>\n","      <td>0.2111</td>\n","      <td>0.0176</td>\n","      <td>0.1348</td>\n","      <td>0.0744</td>\n","      <td>0.0130</td>\n","      <td>0.0106</td>\n","      <td>0.0033</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>0.0881</td>\n","      <td>0.1992</td>\n","      <td>0.0184</td>\n","      <td>0.2261</td>\n","      <td>0.1729</td>\n","      <td>0.2131</td>\n","      <td>0.0693</td>\n","      <td>0.2281</td>\n","      <td>0.4060</td>\n","      <td>0.3973</td>\n","      <td>0.2741</td>\n","      <td>0.3690</td>\n","      <td>0.5556</td>\n","      <td>0.4846</td>\n","      <td>0.3140</td>\n","      <td>0.5334</td>\n","      <td>0.5256</td>\n","      <td>0.2520</td>\n","      <td>0.2090</td>\n","      <td>0.3559</td>\n","      <td>0.6260</td>\n","      <td>0.7340</td>\n","      <td>0.6120</td>\n","      <td>0.3497</td>\n","      <td>0.3953</td>\n","      <td>0.3012</td>\n","      <td>0.5408</td>\n","      <td>0.8814</td>\n","      <td>0.9857</td>\n","      <td>0.9167</td>\n","      <td>0.6121</td>\n","      <td>0.5006</td>\n","      <td>0.3210</td>\n","      <td>0.3202</td>\n","      <td>0.4295</td>\n","      <td>0.3654</td>\n","      <td>0.2655</td>\n","      <td>0.1576</td>\n","      <td>0.0681</td>\n","      <td>0.0294</td>\n","      <td>0.0241</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>0.4152</td>\n","      <td>0.3952</td>\n","      <td>0.4256</td>\n","      <td>0.4135</td>\n","      <td>0.4528</td>\n","      <td>0.5326</td>\n","      <td>0.7306</td>\n","      <td>0.6193</td>\n","      <td>0.2032</td>\n","      <td>0.4636</td>\n","      <td>0.4148</td>\n","      <td>0.4292</td>\n","      <td>0.5730</td>\n","      <td>0.5399</td>\n","      <td>0.3161</td>\n","      <td>0.2285</td>\n","      <td>0.6995</td>\n","      <td>1.0000</td>\n","      <td>0.7262</td>\n","      <td>0.4724</td>\n","      <td>0.5103</td>\n","      <td>0.5459</td>\n","      <td>0.2881</td>\n","      <td>0.0981</td>\n","      <td>0.1951</td>\n","      <td>0.4181</td>\n","      <td>0.4604</td>\n","      <td>0.3217</td>\n","      <td>0.2828</td>\n","      <td>0.2430</td>\n","      <td>0.1979</td>\n","      <td>0.2444</td>\n","      <td>0.1847</td>\n","      <td>0.0841</td>\n","      <td>0.0692</td>\n","      <td>0.0528</td>\n","      <td>0.0357</td>\n","      <td>0.0085</td>\n","      <td>0.0230</td>\n","      <td>0.0046</td>\n","      <td>0.0156</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0286</td>\n","      <td>0.0453</td>\n","      <td>0.0277</td>\n","      <td>0.0174</td>\n","      <td>0.0384</td>\n","      <td>0.0990</td>\n","      <td>0.1201</td>\n","      <td>0.1833</td>\n","      <td>0.2105</td>\n","      <td>0.3039</td>\n","      <td>0.2988</td>\n","      <td>0.4250</td>\n","      <td>0.6343</td>\n","      <td>0.8198</td>\n","      <td>1.0000</td>\n","      <td>0.9988</td>\n","      <td>0.9508</td>\n","      <td>0.9025</td>\n","      <td>0.7234</td>\n","      <td>0.5122</td>\n","      <td>0.2074</td>\n","      <td>0.3985</td>\n","      <td>0.5890</td>\n","      <td>0.2872</td>\n","      <td>0.2043</td>\n","      <td>0.5782</td>\n","      <td>0.5389</td>\n","      <td>0.3750</td>\n","      <td>0.3411</td>\n","      <td>0.5067</td>\n","      <td>0.5580</td>\n","      <td>0.4778</td>\n","      <td>0.3299</td>\n","      <td>0.2198</td>\n","      <td>0.1407</td>\n","      <td>0.2856</td>\n","      <td>0.3807</td>\n","      <td>0.4158</td>\n","      <td>0.4054</td>\n","      <td>0.3296</td>\n","      <td>0.2707</td>\n","      <td>0.2650</td>\n","      <td>0.0723</td>\n","      <td>0.1238</td>\n","      <td>0.1192</td>\n","      <td>0.1089</td>\n","      <td>0.0623</td>\n","      <td>0.0494</td>\n","      <td>0.0264</td>\n","      <td>0.0081</td>\n","      <td>0.0104</td>\n","      <td>0.0045</td>\n","      <td>0.0014</td>\n","      <td>0.0038</td>\n","      <td>0.0013</td>\n","      <td>0.0089</td>\n","      <td>0.0057</td>\n","      <td>0.0027</td>\n","      <td>0.0051</td>\n","      <td>0.0062</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>202</th>\n","      <td>0.0187</td>\n","      <td>0.0346</td>\n","      <td>0.0168</td>\n","      <td>0.0177</td>\n","      <td>0.0393</td>\n","      <td>0.1630</td>\n","      <td>0.2028</td>\n","      <td>0.1694</td>\n","      <td>0.2328</td>\n","      <td>0.2684</td>\n","      <td>0.3108</td>\n","      <td>0.2933</td>\n","      <td>0.2275</td>\n","      <td>0.0994</td>\n","      <td>0.1801</td>\n","      <td>0.2200</td>\n","      <td>0.2732</td>\n","      <td>0.2862</td>\n","      <td>0.2034</td>\n","      <td>0.1740</td>\n","      <td>0.4130</td>\n","      <td>0.6879</td>\n","      <td>0.8120</td>\n","      <td>0.8453</td>\n","      <td>0.8919</td>\n","      <td>0.9300</td>\n","      <td>0.9987</td>\n","      <td>1.0000</td>\n","      <td>0.8104</td>\n","      <td>0.6199</td>\n","      <td>0.6041</td>\n","      <td>0.5547</td>\n","      <td>0.4160</td>\n","      <td>0.1472</td>\n","      <td>0.0849</td>\n","      <td>0.0608</td>\n","      <td>0.0969</td>\n","      <td>0.1411</td>\n","      <td>0.1676</td>\n","      <td>0.1200</td>\n","      <td>0.1201</td>\n","      <td>0.1036</td>\n","      <td>0.1977</td>\n","      <td>0.1339</td>\n","      <td>0.0902</td>\n","      <td>0.1085</td>\n","      <td>0.1521</td>\n","      <td>0.1363</td>\n","      <td>0.0858</td>\n","      <td>0.0290</td>\n","      <td>0.0203</td>\n","      <td>0.0116</td>\n","      <td>0.0098</td>\n","      <td>0.0199</td>\n","      <td>0.0033</td>\n","      <td>0.0101</td>\n","      <td>0.0065</td>\n","      <td>0.0115</td>\n","      <td>0.0193</td>\n","      <td>0.0157</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>203</th>\n","      <td>0.0323</td>\n","      <td>0.0101</td>\n","      <td>0.0298</td>\n","      <td>0.0564</td>\n","      <td>0.0760</td>\n","      <td>0.0958</td>\n","      <td>0.0990</td>\n","      <td>0.1018</td>\n","      <td>0.1030</td>\n","      <td>0.2154</td>\n","      <td>0.3085</td>\n","      <td>0.3425</td>\n","      <td>0.2990</td>\n","      <td>0.1402</td>\n","      <td>0.1235</td>\n","      <td>0.1534</td>\n","      <td>0.1901</td>\n","      <td>0.2429</td>\n","      <td>0.2120</td>\n","      <td>0.2395</td>\n","      <td>0.3272</td>\n","      <td>0.5949</td>\n","      <td>0.8302</td>\n","      <td>0.9045</td>\n","      <td>0.9888</td>\n","      <td>0.9912</td>\n","      <td>0.9448</td>\n","      <td>1.0000</td>\n","      <td>0.9092</td>\n","      <td>0.7412</td>\n","      <td>0.7691</td>\n","      <td>0.7117</td>\n","      <td>0.5304</td>\n","      <td>0.2131</td>\n","      <td>0.0928</td>\n","      <td>0.1297</td>\n","      <td>0.1159</td>\n","      <td>0.1226</td>\n","      <td>0.1768</td>\n","      <td>0.0345</td>\n","      <td>0.1562</td>\n","      <td>0.0824</td>\n","      <td>0.1149</td>\n","      <td>0.1694</td>\n","      <td>0.0954</td>\n","      <td>0.0080</td>\n","      <td>0.0790</td>\n","      <td>0.1255</td>\n","      <td>0.0647</td>\n","      <td>0.0179</td>\n","      <td>0.0051</td>\n","      <td>0.0061</td>\n","      <td>0.0093</td>\n","      <td>0.0135</td>\n","      <td>0.0063</td>\n","      <td>0.0063</td>\n","      <td>0.0034</td>\n","      <td>0.0032</td>\n","      <td>0.0062</td>\n","      <td>0.0067</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>204</th>\n","      <td>0.0522</td>\n","      <td>0.0437</td>\n","      <td>0.0180</td>\n","      <td>0.0292</td>\n","      <td>0.0351</td>\n","      <td>0.1171</td>\n","      <td>0.1257</td>\n","      <td>0.1178</td>\n","      <td>0.1258</td>\n","      <td>0.2529</td>\n","      <td>0.2716</td>\n","      <td>0.2374</td>\n","      <td>0.1878</td>\n","      <td>0.0983</td>\n","      <td>0.0683</td>\n","      <td>0.1503</td>\n","      <td>0.1723</td>\n","      <td>0.2339</td>\n","      <td>0.1962</td>\n","      <td>0.1395</td>\n","      <td>0.3164</td>\n","      <td>0.5888</td>\n","      <td>0.7631</td>\n","      <td>0.8473</td>\n","      <td>0.9424</td>\n","      <td>0.9986</td>\n","      <td>0.9699</td>\n","      <td>1.0000</td>\n","      <td>0.8630</td>\n","      <td>0.6979</td>\n","      <td>0.7717</td>\n","      <td>0.7305</td>\n","      <td>0.5197</td>\n","      <td>0.1786</td>\n","      <td>0.1098</td>\n","      <td>0.1446</td>\n","      <td>0.1066</td>\n","      <td>0.1440</td>\n","      <td>0.1929</td>\n","      <td>0.0325</td>\n","      <td>0.1490</td>\n","      <td>0.0328</td>\n","      <td>0.0537</td>\n","      <td>0.1309</td>\n","      <td>0.0910</td>\n","      <td>0.0757</td>\n","      <td>0.1059</td>\n","      <td>0.1005</td>\n","      <td>0.0535</td>\n","      <td>0.0235</td>\n","      <td>0.0155</td>\n","      <td>0.0160</td>\n","      <td>0.0029</td>\n","      <td>0.0051</td>\n","      <td>0.0062</td>\n","      <td>0.0089</td>\n","      <td>0.0140</td>\n","      <td>0.0138</td>\n","      <td>0.0077</td>\n","      <td>0.0031</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>205</th>\n","      <td>0.0303</td>\n","      <td>0.0353</td>\n","      <td>0.0490</td>\n","      <td>0.0608</td>\n","      <td>0.0167</td>\n","      <td>0.1354</td>\n","      <td>0.1465</td>\n","      <td>0.1123</td>\n","      <td>0.1945</td>\n","      <td>0.2354</td>\n","      <td>0.2898</td>\n","      <td>0.2812</td>\n","      <td>0.1578</td>\n","      <td>0.0273</td>\n","      <td>0.0673</td>\n","      <td>0.1444</td>\n","      <td>0.2070</td>\n","      <td>0.2645</td>\n","      <td>0.2828</td>\n","      <td>0.4293</td>\n","      <td>0.5685</td>\n","      <td>0.6990</td>\n","      <td>0.7246</td>\n","      <td>0.7622</td>\n","      <td>0.9242</td>\n","      <td>1.0000</td>\n","      <td>0.9979</td>\n","      <td>0.8297</td>\n","      <td>0.7032</td>\n","      <td>0.7141</td>\n","      <td>0.6893</td>\n","      <td>0.4961</td>\n","      <td>0.2584</td>\n","      <td>0.0969</td>\n","      <td>0.0776</td>\n","      <td>0.0364</td>\n","      <td>0.1572</td>\n","      <td>0.1823</td>\n","      <td>0.1349</td>\n","      <td>0.0849</td>\n","      <td>0.0492</td>\n","      <td>0.1367</td>\n","      <td>0.1552</td>\n","      <td>0.1548</td>\n","      <td>0.1319</td>\n","      <td>0.0985</td>\n","      <td>0.1258</td>\n","      <td>0.0954</td>\n","      <td>0.0489</td>\n","      <td>0.0241</td>\n","      <td>0.0042</td>\n","      <td>0.0086</td>\n","      <td>0.0046</td>\n","      <td>0.0126</td>\n","      <td>0.0036</td>\n","      <td>0.0035</td>\n","      <td>0.0034</td>\n","      <td>0.0079</td>\n","      <td>0.0036</td>\n","      <td>0.0048</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>206</th>\n","      <td>0.0260</td>\n","      <td>0.0363</td>\n","      <td>0.0136</td>\n","      <td>0.0272</td>\n","      <td>0.0214</td>\n","      <td>0.0338</td>\n","      <td>0.0655</td>\n","      <td>0.1400</td>\n","      <td>0.1843</td>\n","      <td>0.2354</td>\n","      <td>0.2720</td>\n","      <td>0.2442</td>\n","      <td>0.1665</td>\n","      <td>0.0336</td>\n","      <td>0.1302</td>\n","      <td>0.1708</td>\n","      <td>0.2177</td>\n","      <td>0.3175</td>\n","      <td>0.3714</td>\n","      <td>0.4552</td>\n","      <td>0.5700</td>\n","      <td>0.7397</td>\n","      <td>0.8062</td>\n","      <td>0.8837</td>\n","      <td>0.9432</td>\n","      <td>1.0000</td>\n","      <td>0.9375</td>\n","      <td>0.7603</td>\n","      <td>0.7123</td>\n","      <td>0.8358</td>\n","      <td>0.7622</td>\n","      <td>0.4567</td>\n","      <td>0.1715</td>\n","      <td>0.1549</td>\n","      <td>0.1641</td>\n","      <td>0.1869</td>\n","      <td>0.2655</td>\n","      <td>0.1713</td>\n","      <td>0.0959</td>\n","      <td>0.0768</td>\n","      <td>0.0847</td>\n","      <td>0.2076</td>\n","      <td>0.2505</td>\n","      <td>0.1862</td>\n","      <td>0.1439</td>\n","      <td>0.1470</td>\n","      <td>0.0991</td>\n","      <td>0.0041</td>\n","      <td>0.0154</td>\n","      <td>0.0116</td>\n","      <td>0.0181</td>\n","      <td>0.0146</td>\n","      <td>0.0129</td>\n","      <td>0.0047</td>\n","      <td>0.0039</td>\n","      <td>0.0061</td>\n","      <td>0.0040</td>\n","      <td>0.0036</td>\n","      <td>0.0061</td>\n","      <td>0.0115</td>\n","      <td>M</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>207 rows Ã— 61 columns</p>\n","</div>"],"text/plain":["     0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032  R\n","0    0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044  R\n","1    0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078  R\n","2    0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117  R\n","3    0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094  R\n","4    0.0286  0.0453  0.0277  0.0174  0.0384  ...  0.0057  0.0027  0.0051  0.0062  R\n","..      ...     ...     ...     ...     ...  ...     ...     ...     ...     ... ..\n","202  0.0187  0.0346  0.0168  0.0177  0.0393  ...  0.0065  0.0115  0.0193  0.0157  M\n","203  0.0323  0.0101  0.0298  0.0564  0.0760  ...  0.0034  0.0032  0.0062  0.0067  M\n","204  0.0522  0.0437  0.0180  0.0292  0.0351  ...  0.0140  0.0138  0.0077  0.0031  M\n","205  0.0303  0.0353  0.0490  0.0608  0.0167  ...  0.0034  0.0079  0.0036  0.0048  M\n","206  0.0260  0.0363  0.0136  0.0272  0.0214  ...  0.0040  0.0036  0.0061  0.0115  M\n","\n","[207 rows x 61 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"QXP4lVdDlEgb","colab_type":"code","colab":{}},"source":["dataset = df.values\n","x = dataset[:,0:60].astype(float)\n","y = dataset[:,60]\n","le = LabelEncoder()\n","le.fit(y)\n","y_encode = le.transform(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_i4c6qUClWsQ","colab_type":"code","colab":{}},"source":["def create_baseline():\n","\t# create model\n","\tmodel = Sequential()\n","\tmodel.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n","\tmodel.add(Dense(30, kernel_initializer='normal', activation='relu'))\n","\tmodel.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","\t# Compile model\n","\tsgd = SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\treturn model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmA2bY7nlaRE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":583},"outputId":"27c0ff2b-ab64-4f07-a667-019e40333497","executionInfo":{"status":"ok","timestamp":1579165324377,"user_tz":-300,"elapsed":47078,"user":{"displayName":"Mehdi Raza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFcVtZea7sFjanyXz-m90MCC3neMbLZTIgurt0EA=s64","userId":"02751970470605007695"}}},"source":["numpy.random.seed(seed)\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=300, batch_size=16, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, x, y_encode, cv=kfold)\n","print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","Baseline: 86.95% (6.90%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3j5z8-Udldvb","colab_type":"code","colab":{}},"source":["def create_dropout():\n","\t# create model\n","  model = Sequential()\n","  model.add(Dense(60, input_dim=60,  kernel_initializer='normal', activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))\n","  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","\t# Compile model\n","  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n","  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8bajNrplhyy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":146},"outputId":"3ac6160f-3383-4278-f239-c48d6904cab1","executionInfo":{"status":"ok","timestamp":1579165458594,"user_tz":-300,"elapsed":59686,"user":{"displayName":"Mehdi Raza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFcVtZea7sFjanyXz-m90MCC3neMbLZTIgurt0EA=s64","userId":"02751970470605007695"}}},"source":["numpy.random.seed(seed)\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_dropout, epochs=300, batch_size=16, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, x, y_encode, cv=kfold)\n","print(\"Visible: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Visible: 79.71% (12.07%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hFGuQLFglkkA","colab_type":"code","colab":{}},"source":["def create_hidden():\n","\t# create model\n","  model = Sequential()\n","  model.add(Dense(60, input_dim=60, kernel_constraint=max_norm(2.) ,  kernel_initializer='normal', activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","\t# Compile model\n","  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n","  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"omHaSJk9lpZN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"37b930f4-3e43-4c9a-fa0d-b4b5a832a441","executionInfo":{"status":"ok","timestamp":1579165578895,"user_tz":-300,"elapsed":71247,"user":{"displayName":"Mehdi Raza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFcVtZea7sFjanyXz-m90MCC3neMbLZTIgurt0EA=s64","userId":"02751970470605007695"}}},"source":["numpy.random.seed(seed)\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_hidden, epochs=300, batch_size=16, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, x, y_encode, cv=kfold)\n","print(\"Hidden: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Hidden: 83.57% (5.89%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lj7KT_5Vltp3","colab_type":"code","colab":{}},"source":["def create_larger():\n","\t# create model\n","  model = Sequential()\n","  model.add(Dense(60, input_dim=60, kernel_constraint=max_norm(2.) ,  kernel_initializer='normal', activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(60, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","\t# Compile model\n","  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n","  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOTQWeWIluZZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"888050c1-a909-4ea6-86cb-66403cd42f13","executionInfo":{"status":"ok","timestamp":1579165687878,"user_tz":-300,"elapsed":95038,"user":{"displayName":"Mehdi Raza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFcVtZea7sFjanyXz-m90MCC3neMbLZTIgurt0EA=s64","userId":"02751970470605007695"}}},"source":["numpy.random.seed(seed)\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=300, batch_size=16, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, x, y_encode, cv=kfold)\n","print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Larger: 67.19% (16.76%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fAclMjdGlwZV","colab_type":"code","colab":{}},"source":["def create_constrain_model():\n","\t# create model\n","  model = Sequential()\n","  model.add(Dense(60, input_dim=60, kernel_constraint=max_norm(3.) ,  kernel_initializer='normal', activation='relu'))\n","  model.add(Dense(30, kernel_constraint=max_norm(2.) , kernel_initializer='normal', activation='relu'))\n","  model.add(Dropout(0.2))\n","  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","\t# Compile model\n","  sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n","  model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8UCRxre7l166","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8a3c11f1-7f46-4954-b60c-bfb25e9eefdd","executionInfo":{"status":"ok","timestamp":1579165938260,"user_tz":-300,"elapsed":111005,"user":{"displayName":"Mehdi Raza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFcVtZea7sFjanyXz-m90MCC3neMbLZTIgurt0EA=s64","userId":"02751970470605007695"}}},"source":["numpy.random.seed(seed)\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_constrain_model, epochs=400, batch_size=16, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, x, y_encode, cv=kfold)\n","print(\"Constraint: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Constraint: 84.05% (7.23%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gBTzFhBjnj-r","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}